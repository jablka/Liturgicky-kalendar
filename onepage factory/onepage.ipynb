{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liturgický kalendár:\n",
    "# 365 dní ako \"one page\" zobrazenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde sú html súbory:\n",
    "data_dir = './data_html/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all html files from data directory \n",
    "# with file name length 15 (meaning particular date like: '2023-01-01.html')\n",
    "\n",
    "# poznámka: \n",
    "# keďže cirkevný rok začína adventom, sú v zip archíve aj dni z predošlého roka (2022)\n",
    "# preto som pre názornosť dal podmienku, aby bral len aktuálny rok 2023 (file.startswith('2023'))\n",
    "html_files = [ file for file in os.listdir(data_dir) \n",
    "                    if file.startswith('2023') and file.endswith(\".html\") and len(file)==15 ]\n",
    "\n",
    "len(html_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vytvoríme si soup1, do ktorého budeme vkladať obsah.\n",
    "\n",
    "fname = html_files[0] # poslúži ľubovoľný prvý súbor\n",
    "with open(data_dir+fname, encoding='utf-8') as f_in:\n",
    "    s = f_in.read()      \n",
    "\n",
    "soup1 = BeautifulSoup(s,'lxml') # \n",
    "soup1.title.string = 'kalendár 2023' # meníme title\n",
    "init_script = copy.copy(soup1.body.script)\n",
    "soup1.body.clear()\n",
    "soup1.body.append(init_script)\n",
    "\n",
    "my_table = soup1.new_tag('table', border=\"1\")\n",
    "soup1.body.append(my_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in html_files:\n",
    "\n",
    "    with open(data_dir+fname, encoding='utf-8') as f_in:\n",
    "        s = f_in.read()            \n",
    "\n",
    "    date_string = fname.removesuffix('.html')\n",
    "    date_object = datetime.strptime(date_string, '%Y-%m-%d')\n",
    "    tyzden = date_object.strftime('%V').removeprefix('0') \n",
    "\n",
    "    new_table_row = soup1.new_tag('tr')\n",
    "    soup1.table.append(new_table_row)\n",
    "\n",
    "    # vypočítame rowspan pre nultý týždeň v roku:\n",
    "    if date_string=='2023-01-01':\n",
    "        calculated = str(((date_object.weekday()+1) % 7)+1)\n",
    "        td_tyzden = soup1.new_tag('td', rowspan=calculated)\n",
    "        td_tyzden.string = f'{tyzden}.\\u00a0týždeň'\n",
    "        new_table_row.append(td_tyzden)        \n",
    "\n",
    "    # každý ďalší tyždeň začína pondelkom, a má rowspan 7.\n",
    "    elif date_object.weekday() == 0: # pondelok\n",
    "        td_tyzden = soup1.new_tag('td', rowspan=\"7\")\n",
    "        td_tyzden.string = f'{tyzden}.\\u00a0týždeň'\n",
    "        new_table_row.append(td_tyzden)\n",
    "\n",
    "    ### soup2\n",
    "    ### \n",
    "    soup2 = BeautifulSoup(s,'lxml') #    \n",
    "    main = soup2.body.div # div class hvr-scl-chldrn-a\n",
    "\n",
    "    elems = main.find_all('div', class_='lcHEADinfo') # mažeme súradnice\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "    \n",
    "    elems = main.find_all('div', class_='lcDENalt') # tu riešime štýlovanie a vigíliu.\n",
    "    for elem in elems:\n",
    "        if 'psv' in elem['class']: # rušíme štýlovanie \n",
    "            elem['class'].remove('psv') # psv ... prikázaný sviatok, rušíme štýlovanie (červený okraj)\n",
    "\n",
    "        h3 = elem.find('h3')                       \n",
    "        if h3:\n",
    "            if h3.get_text().startswith('Vigília'): # ak je to vigília, mažeme.\n",
    "                elem.extract()  \n",
    "\n",
    "    elems = main.find_all('div', class_='lcBODY') # čítania mažeme\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "\n",
    "    # main.find('div', class_='lcNAVIG').extract()    \n",
    "    main.section.div.extract() # <div class=\"lcNAVIG\"> # navigačné tlačidlá mažeme    \n",
    "\n",
    "    # h1\n",
    "    novy_link = 'onepage_tabulka.html#'+main.h1.a['href'].removesuffix('.html') # upravujeme link\n",
    "    main.h1.a['href'] = novy_link\n",
    "    main.h1.a.string = main.h1.a.string[:-5] # mažeme rok 2023 z textu linku\n",
    "    main.h1.span.find('span', class_='lcWD').append(soup2.new_tag('br')) # <br> \n",
    "    main.h1.span.find('span', class_='lcDMY').append(soup2.new_tag('br')) # <br>\n",
    "    for elem in main.find_all('h1'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "    for elem in main.find_all('h2'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "\n",
    "    # td1 bude obsahovať: datum (lcDMY) a deň v týždni (lcWD)\n",
    "    td1 = soup1.new_tag('td', id=date_string) # id='2023-01-01' napríklad. využije sa pri naDnes navigácii\n",
    "    td1.append( main.find('span', class_='lcDMY') ) # appending is also moving...   \n",
    "    td1.append( main.find('span', class_='lcWD') ) # appending is also moving...\n",
    "    new_table_row.append(td1) # <tr><td>    \n",
    "\n",
    "    # td2 bude obsahovať: meniny (lcND) a zvyšok main soup.\n",
    "    td2 = soup1.new_tag('td')\n",
    "    td2.append( main.find('span', class_='lcND') ) # appending is also moving...\n",
    "    td2.append( main.section ) # appending the rest, which is <section> under <div class=\"lc hvr-scl-chldrn-a\">\n",
    "    new_table_row.append(td2) # <tr><td>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleaning (size reducing)\n",
    "\n",
    "# removing html comments <!-- -->\n",
    "comments = soup1.find_all(string = lambda x: isinstance(x, Comment))\n",
    "for comment in comments:\n",
    "    comment.extract()\n",
    "\n",
    "# removing tags with no content https://stackoverflow.com/questions/33500888/how-to-remove-tags-that-have-no-content\n",
    "for x in soup1.find_all():\n",
    "    if (len(x.get_text(strip=True)) == 0) and (x.name not in ['br', 'img', 'meta', 'link', 'script']):\n",
    "        x.extract()\n",
    "\n",
    "# removing redundant new_lines:\n",
    "# out_string = str(soup1).replace('\\n\\n\\n','\\n')\n",
    "out_string = str(soup1)\n",
    "out_string = re.sub('\\n \\n', '\\n', out_string)\n",
    "out_string = re.sub('\\n\\n', '\\n', out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('onepage.html', mode='w', encoding='utf-8') as f_out:\n",
    "    f_out.write(out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
