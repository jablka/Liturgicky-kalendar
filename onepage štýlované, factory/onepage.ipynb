{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liturgický kalendár: 365 dní ako \"one page\" zobrazenie.\n",
    "# poznámka: po vygenerovaní html súboru je potrebné ešte manuálne vložiť javascript a štýlovanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde sú html súbory:\n",
    "data_dir = './data_html/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all html files from data directory \n",
    "# with file name length 15 (meaning particular date like: '2023-01-01.html')\n",
    "\n",
    "# poznámka: \n",
    "# keďže cirkevný rok začína adventom, sú v zip archíve aj dni z predošlého roka (2022)\n",
    "# preto som pre názornosť dal podmienku, aby bral len aktuálny rok 2023 (file.startswith('2023'))\n",
    "html_files = [ file for file in os.listdir(data_dir) \n",
    "                    if file.startswith('2023') and file.endswith(\".html\") and len(file)==15 ]\n",
    "\n",
    "len(html_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mustra=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"sk\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Liturgický kalendár 2023, skúšobná verzia</title>\n",
    "    <script></script>\n",
    "    <style></style>\n",
    "</head>\n",
    "<body id=\"lc\">\n",
    "    <script>init();</script>\n",
    "</body>\n",
    "<script>\n",
    "    naDnes();\n",
    "</script>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(mustra,'lxml')\n",
    "\n",
    "my_table = soup1.new_tag('table') \n",
    "soup1.body.append(my_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for fname in html_files:\n",
    "\n",
    "    with open(data_dir+fname, encoding='utf-8') as f_in:\n",
    "        s = f_in.read()            \n",
    "\n",
    "    date_string = fname.removesuffix('.html')\n",
    "\n",
    "    # týždne sú oddelené hrubšími čiarami, jednotlivé týždne sú zabalené v <tbody> elementoch\n",
    "    current_date = pd.to_datetime(date_string)\n",
    "    if (date_string == '2023-01-01') or current_date.day_name('sk_SK')=='Pondelok':\n",
    "        tbody_here = soup1.new_tag('tbody') # create new tbody here\n",
    "        soup1.table.append(tbody_here)\n",
    "\n",
    "    new_table_row = soup1.new_tag('tr')\n",
    "    tbody_here.append(new_table_row)\n",
    "\n",
    "    ### soup2\n",
    "    ### \n",
    "    soup2 = BeautifulSoup(s,'lxml') #    \n",
    "    main = soup2.body.div # div class hvr-scl-chldrn-a\n",
    "\n",
    "    elems = main.find_all('div', class_='lcHEADinfo') # mažeme súradnice\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "    \n",
    "    elems = main.find_all('div', class_='lcDENalt') # tu riešime štýlovanie a vigíliu.\n",
    "    for elem in elems:\n",
    "        if 'psv' in elem['class']: # rušíme štýlovanie \n",
    "            elem['class'].remove('psv') # psv ... prikázaný sviatok, rušíme štýlovanie (červený okraj)\n",
    "\n",
    "        h3 = elem.find('h3')                       \n",
    "        if h3:\n",
    "            if h3.get_text().startswith('Vigília'): # ak je to vigília, mažeme.\n",
    "                elem.extract()  \n",
    "\n",
    "    elems = main.find_all('div', class_='lcBODY') # čítania mažeme\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "\n",
    "    # main.find('div', class_='lcNAVIG').extract()    \n",
    "    main.section.div.extract() # <div class=\"lcNAVIG\"> # navigačné tlačidlá mažeme    \n",
    "\n",
    "    # h1\n",
    "    # mažeme link, aj nadbytočný <span> :\n",
    "    main.h1.a.unwrap() #  lcMY\n",
    "    main.h1.span.find('span', class_='lcMD').unwrap() # lcMD\n",
    "    span_lcDMY = main.h1.span.find('span', class_='lcDMY') # lcDMY\n",
    "    span_lcDMY.smooth()\n",
    "    span_lcDMY.string = span_lcDMY.string[:-5] # mažeme rok 2023 z textu\n",
    "\n",
    "    main.h1.span.find('span', class_='lcWD').append(soup2.new_tag('br')) # <br> \n",
    "    main.h1.span.find('span', class_='lcDMY').append(soup2.new_tag('br')) # <br>\n",
    "    for elem in main.find_all('h1'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "    for elem in main.find_all('h2'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "\n",
    "    # td1 bude obsahovať: datum (lcDMY) a deň v týždni (lcWD)\n",
    "    td1 = soup1.new_tag('td', id=date_string) # id='2023-01-01' napríklad. využije sa pri naDnes navigácii\n",
    "    td1.append( main.find('span', class_='lcDMY') ) # appending is also moving...   \n",
    "    td1.append( main.find('span', class_='lcWD') ) # appending is also moving...\n",
    "    new_table_row.append(td1) # <tr><td>    \n",
    "\n",
    "    # td2 bude obsahovať: meniny (lcND) a zvyšok main soup.\n",
    "    td2 = soup1.new_tag('td')\n",
    "    td2.append( main.find('span', class_='lcND') ) # appending is also moving...\n",
    "    for elem in main.find_all('div', class_='lcHEAD'):\n",
    "        td2.append(elem)\n",
    "        \n",
    "    new_table_row.append(td2) # <tr><td>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleaning (size reducing)\n",
    "\n",
    "# removing html comments <!-- -->\n",
    "comments = soup1.find_all(string = lambda x: isinstance(x, Comment))\n",
    "for comment in comments:\n",
    "    comment.extract()\n",
    "\n",
    "# removing tags with no content https://stackoverflow.com/questions/33500888/how-to-remove-tags-that-have-no-content\n",
    "for x in soup1.find_all():\n",
    "    if (len(x.get_text(strip=True)) == 0) and (x.name not in ['br', 'img', 'meta', 'link', 'script']):\n",
    "        x.extract()\n",
    "\n",
    "# soup1.smooth() # optionally\n",
    "\n",
    "with open('onepage.html', mode='w', encoding='utf-8') as f_out:\n",
    "    f_out.write(str(soup1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
