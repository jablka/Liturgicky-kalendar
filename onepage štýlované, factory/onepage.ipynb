{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liturgický kalendár:\n",
    "# 365 dní ako \"one page\" zobrazenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import copy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde sú html súbory:\n",
    "data_dir = './data_html/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all html files from data directory \n",
    "# with file name length 15 (meaning particular date like: '2023-01-01.html')\n",
    "\n",
    "# poznámka: \n",
    "# keďže cirkevný rok začína adventom, sú v zip archíve aj dni z predošlého roka (2022)\n",
    "# preto som pre názornosť dal podmienku, aby bral len aktuálny rok 2023 (file.startswith('2023'))\n",
    "html_files = [ file for file in os.listdir(data_dir) \n",
    "                    if file.startswith('2023') and file.endswith(\".html\") and len(file)==15 ]\n",
    "\n",
    "len(html_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table_style=\"\"\"\n",
    "<style>\n",
    "    table {\n",
    "        /* width: 75%; \n",
    "        margin-left: auto; \n",
    "        margin-right: auto;\n",
    "        font-family: Arial, Helvetica, sans-serif; \n",
    "        line-height: 1.5; */\n",
    "        border: 1px solid gray; \n",
    "        border-collapse: collapse; \n",
    "        /* padding: 1rem;     */\n",
    "    }\n",
    "\n",
    "    td {\n",
    "        /* white-space: pre-wrap; */\n",
    "        border: 1px solid gray;\n",
    "        border-collapse: collapse;\n",
    "        /* padding: 1rem;         */\n",
    "    }\n",
    "\n",
    "    th {\n",
    "        /* font-size: 1.1rem; */\n",
    "        border: 1px solid gray;\n",
    "        border-collapse: collapse;\n",
    "        /* padding: 1rem;           */\n",
    "    }\n",
    "\n",
    "    tbody {\n",
    "        border-style: ridge;\n",
    "        border-width: 5px;\n",
    "        border-color: coral\n",
    "    }\n",
    "\n",
    "    tr td:first-child {\n",
    "        text-align: center;\n",
    "    }    \n",
    "</style>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_style = BeautifulSoup(my_table_style,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# vytvoríme si soup1, do ktorého budeme vkladať obsah.\n",
    "\n",
    "fname = html_files[0] # poslúži ľubovoľný prvý súbor\n",
    "with open(data_dir+fname, encoding='utf-8') as f_in:\n",
    "    s = f_in.read()      \n",
    "\n",
    "soup1 = BeautifulSoup(s,'lxml') # \n",
    "\n",
    "soup1.head.append(soup_style)\n",
    "\n",
    "soup1.title.string = 'kalendár 2023' # meníme title\n",
    "init_script = copy.copy(soup1.body.script)\n",
    "soup1.body.clear()\n",
    "soup1.body.append(init_script)\n",
    "\n",
    "my_table = soup1.new_tag('table') # preč: , border=\"1\"\n",
    "soup1.body.append(my_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in html_files:\n",
    "\n",
    "    with open(data_dir+fname, encoding='utf-8') as f_in:\n",
    "        s = f_in.read()            \n",
    "\n",
    "    date_string = fname.removesuffix('.html')\n",
    "\n",
    "    # týždne sú oddelené hrubšími čiarami, jednotlivé týždne sú zabalené v <tbody> elementoch\n",
    "    current_date = pd.to_datetime(date_string)\n",
    "    if (date_string == '2023-01-01') or current_date.day_name('sk_SK')=='Pondelok':\n",
    "        tbody_here = soup1.new_tag('tbody') # create new tbody here\n",
    "        soup1.table.append(tbody_here)\n",
    "\n",
    "    new_table_row = soup1.new_tag('tr')\n",
    "    tbody_here.append(new_table_row)\n",
    "\n",
    "    ### soup2\n",
    "    ### \n",
    "    soup2 = BeautifulSoup(s,'lxml') #    \n",
    "    main = soup2.body.div # div class hvr-scl-chldrn-a\n",
    "\n",
    "    elems = main.find_all('div', class_='lcHEADinfo') # mažeme súradnice\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "    \n",
    "    elems = main.find_all('div', class_='lcDENalt') # tu riešime štýlovanie a vigíliu.\n",
    "    for elem in elems:\n",
    "        if 'psv' in elem['class']: # rušíme štýlovanie \n",
    "            elem['class'].remove('psv') # psv ... prikázaný sviatok, rušíme štýlovanie (červený okraj)\n",
    "\n",
    "        h3 = elem.find('h3')                       \n",
    "        if h3:\n",
    "            if h3.get_text().startswith('Vigília'): # ak je to vigília, mažeme.\n",
    "                elem.extract()  \n",
    "\n",
    "    elems = main.find_all('div', class_='lcBODY') # čítania mažeme\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "\n",
    "    # main.find('div', class_='lcNAVIG').extract()    \n",
    "    main.section.div.extract() # <div class=\"lcNAVIG\"> # navigačné tlačidlá mažeme    \n",
    "\n",
    "    # h1\n",
    "    novy_link = 'onepage_tabulka.html#'+main.h1.a['href'].removesuffix('.html') # upravujeme link\n",
    "    main.h1.a['href'] = novy_link\n",
    "    main.h1.a.string = main.h1.a.string[:-5] # mažeme rok 2023 z textu linku\n",
    "    main.h1.span.find('span', class_='lcWD').append(soup2.new_tag('br')) # <br> \n",
    "    main.h1.span.find('span', class_='lcDMY').append(soup2.new_tag('br')) # <br>\n",
    "    for elem in main.find_all('h1'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "    for elem in main.find_all('h2'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "\n",
    "    # td1 bude obsahovať: datum (lcDMY) a deň v týždni (lcWD)\n",
    "    td1 = soup1.new_tag('td', id=date_string) # id='2023-01-01' napríklad. využije sa pri naDnes navigácii\n",
    "    td1.append( main.find('span', class_='lcDMY') ) # appending is also moving...   \n",
    "    td1.append( main.find('span', class_='lcWD') ) # appending is also moving...\n",
    "    new_table_row.append(td1) # <tr><td>    \n",
    "\n",
    "    # td2 bude obsahovať: meniny (lcND) a zvyšok main soup.\n",
    "    td2 = soup1.new_tag('td')\n",
    "    td2.append( main.find('span', class_='lcND') ) # appending is also moving...\n",
    "    td2.append( main.section ) # appending the rest, which is <section> under <div class=\"lc hvr-scl-chldrn-a\">\n",
    "    new_table_row.append(td2) # <tr><td>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleaning (size reducing)\n",
    "\n",
    "# removing html comments <!-- -->\n",
    "comments = soup1.find_all(string = lambda x: isinstance(x, Comment))\n",
    "for comment in comments:\n",
    "    comment.extract()\n",
    "\n",
    "# removing tags with no content https://stackoverflow.com/questions/33500888/how-to-remove-tags-that-have-no-content\n",
    "for x in soup1.find_all():\n",
    "    if (len(x.get_text(strip=True)) == 0) and (x.name not in ['br', 'img', 'meta', 'link', 'script']):\n",
    "        x.extract()\n",
    "\n",
    "# removing redundant new_lines:\n",
    "# out_string = str(soup1).replace('\\n\\n\\n','\\n')\n",
    "out_string = str(soup1)\n",
    "out_string = re.sub('\\n \\n', '\\n', out_string)\n",
    "out_string = re.sub('\\n\\n', '\\n', out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('onepage.html', mode='w', encoding='utf-8') as f_out:\n",
    "    f_out.write(out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
