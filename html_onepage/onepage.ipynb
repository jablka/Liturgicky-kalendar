{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liturgický kalendár:\n",
    "# 365 dní ako \"one page\" zobrazenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde sú html súbory:\n",
    "data_dir = './data_html/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all html files from data directory with file name length 15 (meaning particular date like: '2023-01-01.html')\n",
    "# poznámka: \n",
    "# keďže cirkevný rok začína adventom, sú v zip archíve aj dni z predošlého roka (2022)\n",
    "# preto som pre názornosť dal podmienku, aby bral len aktuálny rok 2023 (file.startswith('2023'))\n",
    "html_files = [ file for file in os.listdir(data_dir) if file.startswith('2023') and file.endswith(\".html\") and len(file)==15 ]\n",
    "\n",
    "len(html_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fname = html_files[0]\n",
    "\n",
    "with open(data_dir+fname, encoding='utf-8') as f_in:\n",
    "    s = f_in.read()      \n",
    "\n",
    "soup1 = BeautifulSoup(s,'lxml') # \n",
    "soup1.title.string = 'kalendár 2023' # meníme title\n",
    "init_script = copy.copy(soup1.body.script)\n",
    "soup1.body.clear()\n",
    "soup1.body.append(init_script)\n",
    "\n",
    "my_table = soup1.new_tag('table')\n",
    "my_table['border']=\"1\" # \n",
    "# my_table = BeautifulSoup('<table border=\"1\"></table>', 'html.parser') # tu musí byť 'html.parser' !\n",
    "soup1.body.append(my_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in html_files:\n",
    "\n",
    "    with open(data_dir+fname, encoding='utf-8') as f_in:\n",
    "        s = f_in.read()            \n",
    "\n",
    "    date_string = fname[:-5]\n",
    "    date_object = datetime.strptime(date_string, '%Y-%m-%d')\n",
    "    tyzden = date_object.strftime('%V')\n",
    "    \n",
    "    if tyzden.startswith('0'):\n",
    "        tyzden = tyzden[1:]\n",
    "\n",
    "    new_table_row = soup1.new_tag('tr')\n",
    "    # new_table_row['id'] = date_string # id='2023-01-01' napríklad\n",
    "    soup1.table.append(new_table_row)\n",
    "        \n",
    "    if date_string=='2023-01-01':\n",
    "        td_tyzden = soup1.new_tag('td')\n",
    "        rowspan = ((date_object.weekday()+1) % 7)+1\n",
    "        td_tyzden['rowspan'] = str(rowspan)\n",
    "        td_tyzden.string = f'{tyzden}.\\u00a0týždeň'\n",
    "        # tyzden +=1\n",
    "        new_table_row.append(td_tyzden)        \n",
    "\n",
    "    elif (date_object.weekday() == 0): # pondelok\n",
    "        td_tyzden = soup1.new_tag('td')\n",
    "        td_tyzden['rowspan'] = \"7\"\n",
    "        td_tyzden.string = f'{tyzden}.\\u00a0týždeň'\n",
    "        # tyzden +=1\n",
    "        new_table_row.append(td_tyzden)\n",
    "\n",
    "    ### soup2\n",
    "    ### \n",
    "    soup2 = BeautifulSoup(s,'lxml') #    \n",
    "    body = soup2.body\n",
    "    \n",
    "    body.script.extract() # init(); preč\n",
    "\n",
    "    elems = body.find_all('div', class_='lcHEADinfo') # mažeme súradnice\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "    \n",
    "    elems = body.find_all('div', class_='lcDENalt') # vigília, mažeme\n",
    "    if 'psv' in elems[0]['class']: # v prvom nájdenom rušíme štýlovanie (druhý aj tak zmažeme)\n",
    "        elems[0]['class'].remove('psv') # prikázaný sviatok štýlovanie rušíme (červený okraj)\n",
    "    if len(elems) == 2:        # vigília je vtedy, ak máme dvakrát lcDENalt       \n",
    "        elems[1].extract()     # vigíliu mažeme     \n",
    "\n",
    "    elems = body.find_all('div', class_='lcBODY') # čítania mažeme\n",
    "    for elem in elems: #  v príslušný deň ich môže byť viac\n",
    "        elem.extract()        \n",
    "\n",
    "    # body.find('div', class_='lcNAVIG').extract()    \n",
    "    body.div.section.div.extract() # <div class=\"lcNAVIG\"> # navigačné tlačidlá mažeme    \n",
    "\n",
    "    povodny_link = body.h1.a['href']\n",
    "    body.h1.a['href'] = 'onepage_tabulka.html#'+povodny_link[:-5] # upravujeme link\n",
    "\n",
    "    body.h1.span.find('span', class_='lcWD').append(soup2.new_tag('br'))\n",
    "\n",
    "    what = body.h1.find('a', class_='lcMY')\n",
    "    what.string = what.string[:-5] # mažeme rok 2023 z textu\n",
    "\n",
    "    body.h1.span.find('span', class_='lcDMY').append(soup2.new_tag('br'))\n",
    "    \n",
    "    for elem in body.find_all('h1'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "\n",
    "    for elem in body.find_all('h2'): # nechceme nadpisy, meníme na div\n",
    "        elem.name = 'div'\n",
    "\n",
    "    td1 = soup1.new_tag('td')\n",
    "    td1['id'] = date_string # id='2023-01-01' napríklad\n",
    "    new_table_row.append(td1) # <tr><td>\n",
    "    what = body.find('span', class_='lcDMY')\n",
    "    td1.append(what) # appending is also moving...   \n",
    "    what = body.find('span', class_='lcWD')\n",
    "    td1.append(what) # appending is also moving...\n",
    "\n",
    "    td2 = soup1.new_tag('td')\n",
    "    new_table_row.append(td2) # <tr><td>\n",
    "    what = body.find('span', class_='lcND')\n",
    "    td2.append(what) # appending is also moving...\n",
    "    td2.append(body.div) # appending the rest (which is <div class=\"lc hvr-scl-chldrn-a\">)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing html comments <!-- -->\n",
    "comments = soup1.find_all(string = lambda x: isinstance(x, Comment))\n",
    "for comment in comments:\n",
    "    comment.extract()\n",
    "\n",
    "# removing tags with no content https://stackoverflow.com/questions/33500888/how-to-remove-tags-that-have-no-content\n",
    "for x in soup1.find_all():\n",
    "    if (len(x.get_text(strip=True)) == 0) and (x.name not in ['br', 'img', 'meta', 'link', 'script']):\n",
    "        x.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('onepage.html', mode='w', encoding='utf-8') as f_out:\n",
    "    f_out.write(str(soup1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
